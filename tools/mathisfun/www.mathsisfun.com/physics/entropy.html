<!DOCTYPE html>
<html lang="en"><!-- #BeginTemplate "/Templates/Main.dwt" --><!-- DW6 -->

<!-- Mirrored from www.mathsisfun.com/physics/entropy.html by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 29 Oct 2022 00:52:10 GMT -->
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">









<!-- #BeginEditable "doctitle" -->
<title>Entropy</title>
<meta name="Description" content="Math explained in easy language, plus puzzles, games, quizzes, worksheets and a forum. For K-12 kids, teachers and parents.">


<!-- #EndEditable -->
<meta name="keywords" content="math, maths, mathematics, school, homework, education">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="HandheldFriendly" content="true">
<meta name="referrer" content="always">
	<link rel="preload" href="../images/style/font-champ-bold.ttf" as="font" type="font/ttf" crossorigin="">
	<link rel="preload" href="../style4.css" as="style">
	<link rel="preload" href="../main4.js" as="script">
<link rel="stylesheet" href="../style4.css">
<script src="../main4.js" defer="defer"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-29771508-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-29771508-1');
</script>
</head>

<body id="bodybg">

	<div id="stt"></div>
	<div id="adTop"></div>
	<header>
	<div id="hdr"></div>
	<div id="tran"></div>
	<div id="adHide"></div>
	<div id="cookOK"></div>
	</header>
	
	<div class="mid">

	<nav>
		<div id="menuWide" class="menu"></div>
		<div id="logo"><a href="../index.html"><img src="../images/style/logo.svg" alt="Math is Fun"></a></div>

		<div id="search" role="search"></div>
		<div id="linkto"></div>
	
		<div id="menuSlim" class="menu"></div>
		<div id="menuTiny" class="menu"></div>
	</nav>
	
	<div id="extra"></div>

<article id="content" role="main">

<!-- #BeginEditable "Body" -->
  
<h1 class="center">Entropy Introduction</h1>



<p class="center">Entropy is a measure of disorder</p>
  
<p>
  You walk into a room and see a table with coins on it.</p>
<p class="center"><img src="images/table-coins.svg" alt="table with coins"></p>
<p>You notice they are all heads up:</p>
<p class="center large">HHHHHH</p>
<p>"Whoa, that seems unlikely" you think. But nice and <b>orderly</b>, right?</p>
<p>You move the table and the vibration causes a coin to flip to tails (T):</p>
<p class="center large">HHHHTH</p>
<p>"Huh, I wonder if I can get it to flip back again?", so you shift the table a bit more and get this:</p>
<p class="center large">HTTHTH</p>
<p>Hmmm... more disorderly. You shift the table a bit more and still get random heads and tails.</p>
<p>To begin with they were very orderly, but now they are disorderly again and again.</p>
<p>We can <b>see </b>they are disorderly, but can we come up with a <b>measure </b>of how disorderly they are?</p>
<p>First, how many possible states can they be in?</p>
<ul>
<li>1 coin can have 2 states: {H, T} </li>
<li>2 coins can have 4 states: {HH, HT, TH, TT} </li>
<li>3 coins can have 8 states: {HHH, HHT, HTH, HTT, THH, THT, TTH, TTT} </li></ul>
<p>They double each time, so 6 coins can have 2<sup>6</sup> = <b>64 states</b></p>
<p>Each state has exactly the same chance, but let us <b>group </b>them by how many tails:</p>
  <div class="simple center">
    
<table>
<tbody>
<tr>
<th>Tails</th>
<th>States</th>
<th>Count of States</th></tr>
<tr>
<td>0</td>
<td>HHHHHH</td>
<td>1</td></tr>
<tr>
<td>1</td>
<td>HHHHHT HHHHTH HHHTHH HHTHHH HTHHHH THHHHH</td>
<td>6</td></tr>
<tr>
<td>2</td>
<td>HHHHTT HHHTHT HHHTTH HHTHHT HHTHTH HHTTHH HTHHHT HTHHTH HTHTHH HTTHHH THHHHT THHHTH THHTHH THTHHH TTHHHH</td>
<td>15</td></tr>
<tr>
<td>3</td>
<td>HHHTTT HHTHTT HHTTHT HHTTTH HTHHTT HTHTHT HTHTTH HTTHHT HTTHTH HTTTHH THHHTT THHTHT THHTTH THTHHT THTHTH THTTHH TTHHHT TTHHTH TTHTHH TTTHHH</td>
<td>20</td></tr>
<tr>
<td>4</td>
<td>HHTTTT HTHTTT HTTHTT HTTTHT HTTTTH THHTTT THTHTT THTTHT THTTTH TTHHTT TTHTHT TTHTTH TTTHHT TTTHTH TTTTHH</td>
<td>15</td></tr>
<tr>
<td>5</td>
<td>HTTTTT THTTTT TTHTTT TTTHTT TTTTHT TTTTTH</td>
<td>6</td></tr>
<tr>
<td>6</td>
<td>TTTTTT</td>
<td>1</td></tr></tbody></table>
  </div>
    
<p>Only 1 of the 64 possibilities is HHHHHH. </p>
<p>A combination of H and T is much more likely.</p>
<p>The counts (1, 6, 15, 20, 15, 6, 1) give a <b>rough </b>idea of disorder, but we can do better! </p>
<p>It turns out that a <a href="../algebra/logarithms.html">logarithm</a> of the <b>number of states</b> is perfect for disorder.</p>
<p>Here we use the natural logarithm "ln" to 2 decimal places: </p>
  <div class="simple center">
    

<table class="center">
<tbody>
<tr>
<th>Tails</th>
<th>States</th>
<th><i><b>ln</b></i>(States)</th></tr>

  <tr>
<td>0</td>
<td>1<br>
</td>
<td>0</td></tr>
<tr>
<td>1</td>
<td>6<br>
</td>
<td>1.79</td></tr>
<tr>
<td>2</td>
<td>15<br>
</td>
<td>2.71</td></tr>
<tr>
<td>3</td>
<td>20<br>
</td>
<td>3.00</td></tr>
<tr>
<td>4</td>
<td>15<br>
</td>
<td>2.71</td></tr>
<tr>
<td>5</td>
<td>6<br>
</td>
<td>1.79</td></tr>
<tr>
<td>6</td>
<td>1<br>
</td>
<td>0</td></tr></tbody></table>
  </div>
<p>And that is Entropy! We throw in a constant "k" and get:</p>
<p class="center large">Entropy = k <i><b>ln</b></i>(States)</p>
<p>Play with it here. Every time a random spot is chosen to be flipped. Are any lines more common? Are any totals more common?</p>
<div class="script" style="height: 330px;">
  images/entropy.js
  </div>
<p>This concept helps explain many things in the world: milk mixing in coffee, movement of heat, pollution, gas dispersing and more.</p>
<p>In the real world there are <b>many </b>more particles, and each particle has <b>many</b> more states, but the same idea applies.</p>
<h2>Gas</h2>
<p>Here is a balloon of gas in a plastic box:</p>
<p class="center"><img src="images/gas-box-stt.svg" alt="gas in balloon in box"></p>
<p>The gas molecules bounce around inside the balloon in different directions at different speeds. </p>
<p>There are <b>many </b>different states the gas can be in. </p>
<p class="center large">By "many" we mean a very very very large number.</p>
<p>The balloon bursts and the gas spreads out into the box.</p>
<p class="center"><img src="images/gas-box-all.svg" alt="gas in balloon in box"></p>
<p></p>
<p>Now there are <b>many more </b>possible states:</p>
<ul>
<li>some of those states have the gas back to the balloon shape again (not likely!)</li>

<li>other states might form the word "HI" (not likely!)</li>
<li>but <b>most of the new states</b> are going to be well spread out in the space available.</li></ul>
<p>So the new states include the old states plus many many more.</p>
<p>The value of <span class="large"><i><b>ln</b></i>(States)</span> is now <b>larger</b>, so entropy has <b>increased</b>.</p>
<p class="center larger">As a general rule <b>entropy increases</b>. </p>
<p> But let us be clear here:</p>
<p>Any <b>one </b>state (imagine we froze time) is just as likely as any other state. </p>
<p>But entropy is about a <b>group </b>or class of states. </p>
<ul>
<li>"All states inside the balloon"</li>
<li>"All states within the whole box"</li></ul>
<p>Similar to the example at the start:</p>
<ul>
<li>"Only 1 Head"</li>
<li>"2 Heads"</li>
<li>"3 Heads"</li>
<li>etc...</li></ul>
<p>In picture form:</p>

    
 
<table class="center" style="text-align:center;">
<tbody>
<tr>
<td><img src="images/gas-box-state2.svg" alt="gas in box 2"><br>1 State</td>
<td>&nbsp; &nbsp; </td>
<td><img src="images/gas-box-state1.svg" alt="gas in box 1"><br>1 State</td></tr>
<tr>
<td rowspan="1" colspan="3" class="larger">Any 1 state is equally likely</td></tr>
</tbody></table>

    

  
<p><br></p>
<table class="center" style="text-align:center;">
<tbody>
<tr>
<td><img src="images/gas-box-all-ball.svg" alt="gas in balloon in box"><br>Many States</td>
<td>&nbsp; &nbsp; </td>
<td><img src="images/gas-box-all.svg" alt="gas in balloon in box"><br>Many <b>Many </b>States</td></tr>
<tr>
<td rowspan="1" colspan="3" class="larger">But groups can have very different numbers of states</td></tr>
</tbody></table>
  
  <div class="words">
    
 
<p>Any single state is called a "microstate". Each are equally likely, no matter how weird they may look.</p>
<p>The groups are called "macrostates", and because they may contain different numbers of microstates they are not equally likely.</p>
 </div>
  
  <h2>Entropy Increases</h2>

<p>With just  6 coins we saw entropy naturally increase, but with some chance of getting lower entropy (HHHHHH has a 1/64 chance)</p>
<p>Now imagine 100 coins: the chance of all heads is less than 0.000 000 000 000 000 000 000 000 000 001, which would be freaky.</p>
<p>Now imagine a drop of water with over 5 x 10<sup>21</sup> atoms (and an atom is more complex than heads or tails). The chance of randomly getting reduced entropy is so ridiculously small that we just say <b>entropy increases</b>.</p>
<p>And this is the main idea behind the <b>Second Law of Thermodynamics</b>. </p>
<h2>Entropy Decreases</h2>
<p>Ah, but we <b>can </b>make entropy decrease <b>in a region</b>, but at the expense of increasing entropy elsewhere. </p>
<p>Examples:</p>
<ul>
<li>A factory that makes neat stacks of paper. The paper is orderly but the factory creates a lot of disorder to make them.</li>
<li>A new building is neat and orderly, but making it created a lot of disorder (quarries, timber mills, steel production, electricity, fuel, etc)</li></ul>
<h2>Physics</h2>
<p>Entropy behaves in predictable ways.</p>
<p>In Physics the basic definition is:</p>
<p class="center large">S = k<sub>B</sub> log(Ω)</p>
<p>Where:</p>
<ul>
<li>S is entropy</li>
<li>k<sub>B</sub> is Boltzmann's Constant</li>
<li>Ω is the number of "Microstates"</li></ul>
<p>Another important formula is:</p>

<p class="center large">ΔS = <span class="intbl"><em>Q</em><strong>T</strong></span></p>
<!-- DELS = Q/T -->
<p>Where:</p>
<ul>
<li>ΔS is the change in entropy</li>
<li>Q is the flow of heat energy in or out of the system</li>
<li>T is temperature</li></ul>
<p>But more details are beyond this introductory page.</p>
<p><br></p>
<div class="def">
  

<h3>Footnote: Logarithm Bases</h3>
<p>We used the natural logarithm because we love it. Other people prefer base 2 or base 10 logarithms. Any base is fine because we can convert between them using constants such as ln(2) or ln(10) like this:</p>
<ul>
<li>log<sub>2</sub>(15) = ln(15)/ln(2)</li>
<li>log<sub>10</sub>(15) = ln(15)/ln(10) </li></ul>
  </div><p><br>
  </p>

<div class="related">  

  <a href="index.html">Physics Index</a>
</div>
<!-- #EndEditable -->

</article>

<div id="adend" class="centerfull noprint"></div>
<footer id="footer" class="centerfull noprint"></footer>
<div id="copyrt">Copyright © 2021 MathsIsFun.com</div>

</div>
</body><!-- #EndTemplate -->
<!-- Mirrored from www.mathsisfun.com/physics/entropy.html by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 29 Oct 2022 00:52:11 GMT -->
</html>